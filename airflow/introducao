# airflow needs a home, ~/airflow is the default,
# but you can lay foundation somewhere else if you prefer
# (optional)
export AIRFLOW_HOME=~/airflow

# install from pypi using pip
pip install apache-airflow

# initialize the database
airflow initdb

# start the web server, default port is 8080
airflow webserver -p 8080

# start the scheduler
airflow scheduler

# visit localhost:8080 in the browser and enable the example dag in the home page


Para simular um ambiente do Airflow na nuvem na sua máquina local, utilize o docker & docker-compose.
https://github.com/puckel/docker-airflow

Será baixado no docker o redis, o postgres, o flower, o webserver, o scheduler e o worker (validar no arquivo docker-compose.yml)

Para iniciar: $ docker-compose up -d
Para parar: $ docker-compose down

Para alterar algum parametro, como a quantidade de workers: $ docker-compose up -d --scale worker=3